{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH02.3. **Gradient Optimization Algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Gradient Optimization Algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : **[CONTENTS]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 종류** : \n",
    "#### $ \\hspace{0.15cm} $ ① Momentum\n",
    "#### $ \\hspace{0.15cm} $ ② Root Mean Square Propagation(RMSProp)\n",
    "#### $ \\hspace{0.15cm} $ ③ Adaptive Moment Estimation(Adam)\n",
    "#### $ \\hspace{0.15cm} $ ④ Learning Rate Decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Momentum**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 기울기의 **1차 모멘트**를 이용하여 일관된 방향으로의 이동을 촉진하는 방법\n",
    "#### $ \\Rightarrow{} \\theta{}^{[l]}_{t} = \\theta{}^{[l]}_{t-1} - \\alpha{} \\cdot{} v^{[l]}_{t} \\;\\; \\text{ where } \\, v^{[l]}_{t} = \\beta{}_{1} \\cdot{} v^{[l]}_{t-1} + (1 - \\beta{}_{1} ) \\cdot{} \\frac{\\partial{}J}{\\partial{}\\theta{}^{[l]}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(`PLUS`) 모멘트(Moment)** : **[CONTENTS]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Root Mean Square Propagation(RMSProp)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : 기울기의 **2차 모멘트**를 이용하여 그라디언트에 따라 학습률(learning rate)을 조정하는 방법\n",
    "#### $ \\Rightarrow{} \\theta{}^{[l]}_{t} = \\theta{}^{[l]}_{t-1} - \\alpha{} \\cdot{} \\frac{1}{s^{[l]}_{t}+\\epsilon{}} \\cdot{} \\frac{\\partial{}J}{\\partial{}\\theta{}^{[l]}} \\;\\; \\text{ where } \\, s^{[l]}_{t} = \\sqrt{\\beta{}_{2} \\cdot{} s^{[l]}_{t-1} + (1 - \\beta{}_{2} ) \\cdot{} \\frac{\\partial{}J}{\\partial{}\\theta{}^{[l]}}} $\n",
    "#### ※ $ \\, \\epsilon{} $ : zero-divison error 방지용 상수, 일반적으로는 $ \\, 10^{-7} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Adaptive Moment Estimation(Adam)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : Momentum과 RMSProp을 모두 이용하여 그라디언트의 일관성과 학습률을 조정하는 방법\n",
    "#### $ \\Rightarrow{} \\theta{}^{[l]}_{t} = \\theta{}^{[l]}_{t-1} - \\alpha{} \\cdot{} \\frac{1}{s^{[l]}_{t}+\\epsilon{}} \\cdot{} v^{[l]}_{t} \\;\\; \\text{ where } \\, v^{[l]}_{t} = \\beta{}_{1} \\cdot{} v^{[l]}_{t-1} + (1 - \\beta{}_{1} ) \\cdot{} \\frac{\\partial{}J}{\\partial{}\\theta{}^{[l]}} $ \n",
    "#### $ \\hspace{4.8cm} \\text{and } \\, s^{[l]}_{t} = \\sqrt{\\beta{}_{2} \\cdot{} s^{[l]}_{t-1} + (1 - \\beta{}_{2} ) \\cdot{} \\frac{\\partial{}J}{\\partial{}\\theta{}^{[l]}}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Learning Rate Decay**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 정의** : **[CONTENTS]**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
