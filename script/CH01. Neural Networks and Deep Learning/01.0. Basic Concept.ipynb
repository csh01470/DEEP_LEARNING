{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH01.0. **Basic Concept**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Standard Notations for Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) 입력(Input)** : \n",
    "#### $ \\hspace{0.15cm} $ ① $ \\, m $ : 데이터셋 샘플 개수\n",
    "#### $ \\hspace{0.15cm} $ ② $ \\, n_{x} = n^{[0]} $ : 특징 개수\n",
    "#### $ \\hspace{0.15cm} $ ③ $ \\, \\underset{n_{x}\\times{}1}{\\textbf{x}^{(i)}} = \\begin{bmatrix} x^{(i)}_{1} \\\\ x^{(i)}_{2} \\\\ \\vdots{} \\\\ x^{(i)}_{n_{x}} \\end{bmatrix} $ : $ \\, i $ 번 째 입력 데이터(벡터)\n",
    "#### $ \\hspace{0.15cm} $ ④ $ \\, \\underset{n_{x}\\times{}m}{X} = \\begin{bmatrix} x^{(1)}_{1} & x^{(2)}_{1} & \\cdots{} & x^{(m)}_{1} \\\\ x^{(1)}_{2} & x^{(2)}_{2} & \\cdots{} & x^{(m)}_{2} \\\\ \\vdots{} & \\vdots{} & \\ddots{} & \\vdots{} \\\\ x^{(1)}_{n_{x}} & x^{(2)}_{n_{x}} & \\cdots{} & x^{(m)}_{n_{x}} \\end{bmatrix} $ : 입력 데이터셋(행렬)\n",
    "#### $ \\hspace{1.375cm} = \\begin{bmatrix} \\textbf{x}^{(1)}&\\textbf{x}^{(2)}&\\cdots{}&\\textbf{x}^{(m)}\\end{bmatrix} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) 출력(Output)** :\n",
    "#### $ \\hspace{0.15cm} $ ① $ \\, n_{y} = n^{[L]} $ : 분류 문제에서 타겟 범주(target class) 개수\n",
    "#### $ \\hspace{0.15cm} $ ② $ \\, \\underset{n_{y}\\times{}1}{\\textbf{y}^{(i)}} = \\begin{bmatrix} y^{(i)}_{1} \\\\ y^{(i)}_{2} \\\\ \\vdots{} \\\\ y^{(i)}_{n_{y}} \\end{bmatrix} $ : $ \\, i $ 번 째 타겟 범주 데이터(벡터)\n",
    "#### $ \\hspace{0.15cm} $ ③ $ \\, \\underset{n_{y}\\times{}m}{Y} $ : 분류 문제에서 타겟 데이터셋(행렬) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 네트워크(Network)** :\n",
    "#### $ \\hspace{0.15cm} $ ① $ \\, L $ : 네트워크의 레이어 개수\n",
    "#### $ \\hspace{0.15cm} $ ② $ \\, n_{h}^{[l]} = n^{[l]} $ : $ \\, l $ 번째 층(layer)의 은닉 노드(hidden node) 개수\n",
    "#### $ \\hspace{0.15cm} $ ③ $ \\, \\underset{n_{h}^{l}\\times{}n_{h}^{l-1}}{W^{[l]}} $ : $ \\, l $ 번 째 층의 은닉 노드 행렬\n",
    "#### $ \\hspace{0.15cm} $ ④ $ \\, \\underset{n_{h}^{l}\\times{}m}{B^{[l]}} $ : $ \\, l $ 번 째 층의 편향(bias) 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(`PLUS`)** 실제 Python에서는 Broad-casting을 이용하기 때문에 편향 행렬을 벡터로 변환하여 정의함\n",
    "#### $ \\hspace{0.15cm} \\Rightarrow{} B^{[l]} \\approx{} \\textbf{b}^{[l](i)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) 순방향 전파(Feed-foward propagation)** :\n",
    "#### $ \\hspace{0.15cm} $ ① $ \\, \\underset{n_{h}^{l}\\times{}1}{\\textbf{z}^{[l](i)}} = W^{[l]}\\textbf{x}^{(i)} + \\textbf{b}^{[l](i)} $ : $ \\, l $ 번 째 층, $ \\, i $ 번 째 데이터의 선형 변환 출력 벡터\n",
    "#### $ \\hspace{0.15cm} $ ② $ \\, \\underset{n_{h}^{l}\\times{}m}{Z^{[l]}} = W^{[l]}X + b^{[l]} $ : $ \\, l $ 번 째 선형 변환 출력 행렬\n",
    "#### $ \\hspace{0.15cm} $ ③ $ \\, \\underset{n_{h}^{l}\\times{}1}{\\textbf{a}^{[l](i)}} = h(\\textbf{z}^{[l](i)})$ : $ \\, l $ 번 째 층, $ \\, i $ 번 째 데이터의 활성화 변환 출력 벡터\n",
    "#### $ \\hspace{0.15cm} $ ④ $ \\, \\underset{n_{h}^{l}\\times{}m}{A^{[l]}} = h(Z^{[l]})$ : $ \\, l $ 번 째 층의 활성화 변환 출력 행렬\n",
    "#### $ \\hspace{0.15cm} $ ⑤ $ \\, \\underset{n_{y}\\times{}m}{\\hat{\\textbf{Y}}} = A^{[L]} $ : $ \\, L $ 번 째 층의 활성화 변환 출력 행렬(예측 행렬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) 역방향 전파(Backward propagation)** : \n",
    "#### $ \\hspace{0.15cm} $ ① $ \\, \\underset{n_{h}^{l}\\times{}1}{\\textbf{z}^{[l](i)}} = W^{[l]}\\textbf{x}^{(i)} + \\textbf{b}^{[l](i)} $ : $ \\, l $ 번 째 층, $ \\, i $ 번 째 데이터의 선형 변환 출력 벡터\n",
    "#### $ \\hspace{0.15cm} $ ② $ \\, \\underset{n_{h}^{l}\\times{}m}{Z^{[l]}} = W^{[l]}X + b^{[l]} $ : $ \\, l $ 번 째 선형 변환 출력 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Activation Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) Sigmoid** : **[CONTENTS]**\n",
    "#### $ \\hspace{0.15cm} $ ①\n",
    "#### $ \\hspace{0.15cm} \\Rightarrow{} f(x) = \\sigma{}(x) = \\frac{1}{1+e^{-x}} $\n",
    "#### $ \\hspace{0.15cm} $ **[GRAPH]**\n",
    "#### $ \\hspace{0.15cm} $ ② 도함수\n",
    "#### $ \\hspace{0.15cm} \\Rightarrow{} f'(x) = f(x) (1-f(x)) $\n",
    "#### $ \\hspace{0.15cm} $ **[GRAPH]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2) Hyperbolic Tangent(tanh)** : **[CONTENTS]**\n",
    "#### $ \\hspace{0.15cm} $ ①\n",
    "#### $ \\hspace{0.15cm} \\Rightarrow{} f(x) = \\text{tanh}(x) = \\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}} $\n",
    "#### $ \\hspace{0.15cm} $ **[GRAPH]**\n",
    "#### $ \\hspace{0.15cm} $ ② 도함수\n",
    "#### $ \\hspace{0.15cm} \\Rightarrow{} f'(x) = 1 - f(x)^{2} $\n",
    "#### $ \\hspace{0.15cm} $ **[GRAPH]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3) Rectified Linear Unit(RELU)** : **[CONTENTS]**\n",
    "#### $ \\hspace{0.15cm} $ ①\n",
    "#### $ \\hspace{0.15cm} \\Rightarrow{} f(x) = \\text{max}(0,\\, x) $\n",
    "#### $ \\hspace{0.15cm} $ **[GRAPH]**\n",
    "#### $ \\hspace{0.15cm} $ ② 도함수\n",
    "#### $ \\hspace{0.15cm} \\Rightarrow{} f'(x) = \\begin{cases} 1, \\;\\; x > 0 \\\\ 0, \\;\\; x \\leq{} 0 \\end{cases} $\n",
    "#### $ \\hspace{0.15cm} $ **[GRAPH]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4) Leaky Rectified Linear Unit(Leaky RELU)** : **[CONTENTS]**\n",
    "#### $ \\hspace{0.15cm} $ ①\n",
    "#### $ \\Rightarrow{} f(x) = \\text{max}(\\alpha{} \\cdot{} x,\\, x) $\n",
    "#### $ \\hspace{0.15cm} $ **[GRAPH]**\n",
    "#### $ \\hspace{0.15cm} $ ② 도함수\n",
    "#### $ \\Leftrightarrow{} f'(x) = \\begin{cases} 1, \\;\\; x > 0 \\\\ \\alpha{}, \\;\\; x \\leq{} 0 \\end{cases} $\n",
    "#### $ \\hspace{0.15cm} $ **[GRAPH]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(5) Exponential Linear Unit (ELU)** : **[CONTENTS]**\n",
    "#### $ \\hspace{0.15cm} $ ①\n",
    "#### $ \\hspace{0.15cm} \\Rightarrow{} f(x) = \\begin{cases} x, \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; x > 0 \\\\ \\alpha{} \\cdot{} ( e^{x} - 1), \\;\\; x \\leq{} 0 \\end{cases} $\n",
    "#### $ \\hspace{0.15cm} $ **[GRAPH]**\n",
    "#### $ \\hspace{0.15cm} $ ② 도함수\n",
    "#### $ \\hspace{0.15cm} \\Rightarrow{} f'(x) = \\begin{cases} 1, \\;\\; x > 0 \\\\ f(x) + \\alpha{}, \\;\\; x \\leq{} 0 \\end{cases} $\n",
    "#### $ \\hspace{0.15cm} $ **[GRAPH]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(6) Swish** : **[CONTENTS]**\n",
    "#### $ \\hspace{0.15cm} $ ①\n",
    "#### $ \\hspace{0.15cm} \\Rightarrow{} f(x) = x \\cdot{} \\sigma{}(\\beta{} \\cdot{} x) = x \\cdot{} \\frac{1}{1+e^{-\\beta{}\\cdot{}x}} $\n",
    "#### $ \\hspace{0.15cm} $ **[GRAPH]**\n",
    "#### $ \\hspace{0.15cm} $ ② 도함수\n",
    "#### $ \\hspace{0.15cm} \\Rightarrow{} f'(x) = f(x) + \\sigma{}(\\beta{} \\cdot{} x)(1 - \\beta{} \\cdot{} f(x)) = \\sigma{}(\\beta{} \\cdot{} x) + \\beta{} \\cdot{} x \\cdot{} \\sigma{}(\\beta{}\\cdot{}x)(1 - \\sigma{}(\\beta{} \\cdot{} x)) $\n",
    "#### $ \\hspace{0.15cm} $ **[GRAPH]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Loss Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1) Log-loss**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
